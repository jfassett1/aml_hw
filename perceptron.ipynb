{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 7\n",
    "\n",
    "\n",
    "a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part a\n",
    "\n",
    "n = 25\n",
    "cluster1 = np.random.randn(n,3) #0 centered\n",
    "\n",
    "cluster1 = np.hstack([cluster1, np.full((n,1),1)])\n",
    "\n",
    "cluster2 = np.random.randn(n,3) + np.array([4,4,4])\n",
    "\n",
    "cluster2 = np.hstack([cluster2, np.full((n,1),-1)])\n",
    "\n",
    "\n",
    "data = np.vstack((cluster1,cluster2))\n",
    "# data.shape\n",
    "x = data[:,:-1] # Main data without labels\n",
    "y = data[:,-1] # Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beta^2 index: 39\n",
      "Beta^2 val: 9.08\n"
     ]
    }
   ],
   "source": [
    "#Part b\n",
    "\n",
    "# x = data[:,:-1]\n",
    "\n",
    "norms = np.linalg.norm(x,axis=1)\n",
    "beta2_i = np.argmax(norms)\n",
    "beta2 = np.max(norms)\n",
    "\n",
    "print(f\"Beta^2 index: {beta2_i}\\nBeta^2 val: {round(beta2,2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Class\n",
    "\n",
    "class Perceptron:\n",
    "    def __init__(self,w,bias=True,constraint=False):\n",
    "        self.bias = bias\n",
    "        self.constraint = constraint\n",
    "        if bias:\n",
    "            self.weights = np.random.randn(w+1)\n",
    "        else:\n",
    "            self.weights = np.random.randn(w)\n",
    "        \n",
    "        if self.constraint:\n",
    "            self.weights /= np.linalg.norm(self.weights)\n",
    "            self.weights *= 0.1\n",
    "            self.w0 = self.weights\n",
    "\n",
    "\n",
    "    def fit_sto(self,data,labels,ret=False,verb=True):\n",
    "        steps = 0\n",
    "        correct = False\n",
    "        if self.bias:\n",
    "            data = add_bias(data)\n",
    "\n",
    "        while not correct:\n",
    "            incorrect = 0\n",
    "            for x,y in zip(data,labels):\n",
    "                score = x @ self.weights * y\n",
    "                # print(x @ self.weights)\n",
    "                if score <= 0:\n",
    "                    self.weights += (y*x)\n",
    "                    steps += 1\n",
    "                    incorrect +=1\n",
    "                    # show(self.weights)\n",
    "                    # sleep(0.5)\n",
    "            if incorrect == 0:\n",
    "                break\n",
    "        if verb:\n",
    "            print(f\"{steps} updates made\")\n",
    "        if ret:\n",
    "            return steps\n",
    "\n",
    "    def fit_batch(self,data,labels,lr = 0.3, theta = 0.15, epochs = 5000):\n",
    "        steps = 0\n",
    "        if self.bias:\n",
    "            data = add_bias(data)\n",
    "\n",
    "        while steps < epochs:\n",
    "            misclassified = (labels * (self.weights @ data.T) <= 0) # Called map because it's used to index. Gives indices of all incorrect\n",
    "            # print(misclassified.shape)\n",
    "            if not np.any(misclassified): # If there are no incorrect\n",
    "                break\n",
    "\n",
    "            update = lr * (labels[None,misclassified,] * data[misclassified].T )\n",
    "\n",
    "            self.weights += update.sum(axis=1)\n",
    "\n",
    "            steps += 1\n",
    "        print(\"Updates:\", steps)\n",
    "\n",
    "\n",
    "\n",
    "    def pred(self,data):\n",
    "        # print(self.weights.shape,data.shape)\n",
    "        if self.bias:\n",
    "            data = add_bias(data)\n",
    "\n",
    "        ypred = np.sign(self.weights @ data.T)\n",
    "        return ypred\n",
    "    \n",
    "\n",
    "def test_init(weights,dim=3):\n",
    "    \"Testing different initialization strategies\"\n",
    "    p = Perceptron(dim)\n",
    "    p.weights = weights\n",
    "    return p.fit_sto(x,y,ret=True,verb=False) #Returns num of steps for convergence\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def add_bias(matrix):\n",
    "    matrix = np.hstack([matrix, np.full((matrix.shape[0],1),1)])\n",
    "    return matrix# print(ypred,\"\\n\",y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updates: 23\n",
      "100.0\n"
     ]
    }
   ],
   "source": [
    "#Part C\n",
    "#It converged relatively quickly.\n",
    "qr = Perceptron(3)\n",
    "\n",
    "qr.fit_batch(x,y)\n",
    "\n",
    "ypred= qr.pred(x)\n",
    "\n",
    "percentage = (np.mean((ypred * y) == 1)) * 100\n",
    "print(percentage)\n",
    "# print(qr.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 updates made\n",
      "100.0\n"
     ]
    }
   ],
   "source": [
    "#Part D & Part E\n",
    "#The spherical constraint was enforced in the __init__ function of the perceptron class.\n",
    "# It is applied when the 'constraint' parameter is set to True\n",
    "qr= Perceptron(3,constraint=True)\n",
    "\n",
    "qr.fit_sto(x,y)\n",
    "\n",
    "ypred= qr.pred(x)\n",
    "\n",
    "percentage = (np.mean((ypred * y) == 1)) * 100\n",
    "print(percentage)\n",
    "w_tilde = qr.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector of Zeros: \n",
      "Num Updates: 7 \n",
      "Upperbound: 49.0 \n",
      "\n",
      "Gaussian Mean 0: \n",
      "Num Updates: 7 \n",
      "Upperbound: 43.0 \n",
      "\n",
      "Gaussian Mean 100: \n",
      "Num Updates: 34 \n",
      "Upperbound: 409.0 \n",
      "\n",
      "Uniform |x| <= 1 \n",
      "Num Updates: 4 \n",
      "Upperbound: 57.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Part F\n",
    "\n",
    "# My algorithm took 12 iterations (may vary if re-run)\n",
    "# The maximum upper bound for my initialization is 20. So it worked well within the bounds\n",
    "\n",
    "data_b = add_bias(x)\n",
    "\n",
    "# print(w_tilde.shape,data_b.shape)\n",
    "gamma = np.min((w_tilde @ data_b.T) * y)\n",
    "alpha = beta2 / gamma\n",
    "def upperbounds(w0,alpha=alpha,w_tilde=w_tilde,beta2=beta2):\n",
    "    k_0 = np.ceil((np.linalg.norm(w0 - alpha * w_tilde) ** 2) / beta2)\n",
    "    return k_0\n",
    "k_0 = upperbounds(qr.w0)\n",
    "\n",
    "\n",
    "mpp = {\n",
    "\"Vector of Zeros:\": np.zeros(4),\n",
    "\"Gaussian Mean 0:\": np.random.randn(4),\n",
    "\"Gaussian Mean 100:\": np.random.randn(4) + np.array([100,100,100,100]),\n",
    "\"Uniform |x| <= 1\": np.random.uniform(-1,1,4)\n",
    "\n",
    "\n",
    "\n",
    "}\n",
    "\n",
    "for k,v in mpp.items():\n",
    "    print(k, \"\\nNum Updates:\", test_init(v), \"\\nUpperbound:\",upperbounds(v),\"\\n\")\n",
    "\n",
    "\n",
    "# print(k_0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w_tilde @ data_b.T * y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# x2 = np.array([\n",
    "# (-1, 0),\n",
    "# (-1, -1),\n",
    "# (-2, 0),\n",
    "# (-2, 1),\n",
    "# (1, 0),\n",
    "# (0, 1),\n",
    "# (0, 2),\n",
    "# (0, 3),\n",
    "# ])\n",
    "\n",
    "\n",
    "# y2 = np.array([-1,-1,-1,-1,1,1,1,1])\n",
    "# # print(x2.shape,y.shape)\n",
    "# w_tilde = np.array([1.,1.])\n",
    "# w_0 = np.zeros_like(w_tilde)\n",
    "# # w_tilde *= 1000000000\n",
    "# # w_tilde *= 0.000001\n",
    "# gamma = np.min(np.linalg.norm(w_tilde @ x2.T * y2.T))\n",
    "\n",
    "# norms = np.linalg.norm(x2,axis=1)\n",
    "# beta2_i = np.argmax(norms)\n",
    "# beta2 = np.max(norms)\n",
    "\n",
    "# # print(np.sign(w_tilde @ x2.T))\n",
    "# w2 =np.linalg.norm(w_tilde)**2 \n",
    "# print(beta2)\n",
    "# print(gamma)\n",
    "# print(beta2 * w2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
